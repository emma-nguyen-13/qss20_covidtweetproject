{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf91359a82611f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Final Project\n",
    "\n",
    "- Main Questions:\n",
    "We aim to understand the correlation between the timing of Twitter account creation and\n",
    "the level of engagement regarding current events in the platform. This could help us determine\n",
    "if certain world events, such as the COVID-19 pandemic or the #BLM movement, influenced the creation of new\n",
    "accounts or if accounts created during specific periods are more active in discussing \"hot topics\".\n",
    "\n",
    "- Data Resources:\n",
    "We would be using the *acc_age* field, which represents the age of the accounts in days and\n",
    "the verified status to measure credibility which potentially affects the account’s engagement\n",
    "and reach. Additionally, by using the accounts’ creation date, we can categorize the accounts\n",
    "by year and find in which year/period were created the highest number of accounts. This\n",
    "could help us determine if accounts created during the pandemic were more engaged in\n",
    "COVID-19 related tweets than older accounts or vice versa. Other relevant fields include\n",
    "date, which indicates when each tweet was posted, allowing us to temporally analyze tweet\n",
    "volume over time. Finally, we would have engagement metrics like rt rt count (retweet\n",
    "count), rt reply count (reply count), and rt fav count (like count), which will help us measure\n",
    "the influence and reach of the tweets from these accounts. By looking at these data fields, we\n",
    "can understand how Twitter accounts created at different times contribute to the discourse\n",
    "on COVID-19, exploring whether significant world events like the pandemic have increased\n",
    "account creations or if these newly created accounts engage differently with the topic.\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dabd9f7-77c7-45f5-a5bd-43bb415ca5cd",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "1. Find first occurrence of each hashtag and compare it to the first news article about the hate crimes\n",
    "2. With acc_age and account_creation_date, create a time series analysis plot to assess how many accounts were created pre- and post- the first occurrence of the hashtag *#COVID* / *#BLM* / *#StopAsianHate* - answer the question **What is the relationship between the onset of these current events and the creation of twitter accounts?**\n",
    "4. Create a time series analysis plot to assess the volume of tweets for each over time (assesing any relationship between tweeting and world events) - answer the question **What is the relationship between the onset of these current events and the volume of tweets?**\n",
    "5. Use sentiment analysis to assess the sentiments of the tweets surrounding these current events - answer the question **What is the language of these tweets?**\n",
    "6. Using the bot dictionary (Professor Chang is sending us a dictionary of bots) are any of these tweets - answer the question **How credible are the accounts tweeting about these current events?**\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87001d-73b6-45cc-9633-47082ad87bbd",
   "metadata": {},
   "source": [
    "### 0A. Exploring the Data\n",
    "What is the data we're looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f8a5c3-612d-44f1-9c61-4911dcbca631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:36:47.240248Z",
     "start_time": "2024-05-17T08:36:46.242723Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#Insert YOUR path to data\n",
    "pickle = \"/Users/emmanguyen/Downloads/BLM_StopAsianHate.pkl\"\n",
    "data = pd.read_pickle(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46238f7c-ae43-4736-afe8-84098438d3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1678460 entries, 1771 to 174882\n",
      "Data columns (total 77 columns):\n",
      " #   Column                 Non-Null Count    Dtype              \n",
      "---  ------                 --------------    -----              \n",
      " 0   tweetid                1678460 non-null  int64              \n",
      " 1   userid                 1678460 non-null  int64              \n",
      " 2   screen_name            1678460 non-null  object             \n",
      " 3   date                   1678460 non-null  datetime64[ns, UTC]\n",
      " 4   lang                   1678460 non-null  object             \n",
      " 5   location               1023285 non-null  object             \n",
      " 6   place_id               12259 non-null    object             \n",
      " 7   place_url              12259 non-null    object             \n",
      " 8   place_type             12259 non-null    object             \n",
      " 9   place_name             12259 non-null    object             \n",
      " 10  place_full_name        12259 non-null    object             \n",
      " 11  place_country_code     12247 non-null    object             \n",
      " 12  place_country          12251 non-null    object             \n",
      " 13  place_bounding_box     12259 non-null    object             \n",
      " 14  text                   1678460 non-null  object             \n",
      " 15  extended               1678460 non-null  object             \n",
      " 16  coord                  542 non-null      object             \n",
      " 17  reply_userid           240025 non-null   float64            \n",
      " 18  reply_screen           240025 non-null   object             \n",
      " 19  reply_statusid         240025 non-null   float64            \n",
      " 20  tweet_type             1678460 non-null  object             \n",
      " 21  friends_count          1678460 non-null  int64              \n",
      " 22  listed_count           1678460 non-null  float64            \n",
      " 23  followers_count        1678460 non-null  int64              \n",
      " 24  favourites_count       1678460 non-null  int64              \n",
      " 25  statuses_count         1678460 non-null  int64              \n",
      " 26  verified               1678460 non-null  bool               \n",
      " 27  hashtag                1678460 non-null  object             \n",
      " 28  urls_list              1678460 non-null  object             \n",
      " 29  profile_pic_url        1311563 non-null  object             \n",
      " 30  profile_banner_url     1311563 non-null  object             \n",
      " 31  display_name           1678384 non-null  object             \n",
      " 32  date_first_tweet       1678460 non-null  object             \n",
      " 33  account_creation_date  1678460 non-null  object             \n",
      " 34  rt_urls_list           1678460 non-null  object             \n",
      " 35  mentionid              1678460 non-null  object             \n",
      " 36  mentionsn              1678460 non-null  object             \n",
      " 37  rt_screen              927556 non-null   object             \n",
      " 38  rt_userid              927556 non-null   float64            \n",
      " 39  rt_text                1111362 non-null  object             \n",
      " 40  rt_hashtag             1678460 non-null  object             \n",
      " 41  rt_qtd_count           1678460 non-null  int64              \n",
      " 42  rt_rt_count            1678460 non-null  float64            \n",
      " 43  rt_reply_count         1678460 non-null  float64            \n",
      " 44  rt_fav_count           1678460 non-null  float64            \n",
      " 45  rt_tweetid             1111362 non-null  float64            \n",
      " 46  rt_location            725519 non-null   object             \n",
      " 47  qtd_screen             279316 non-null   object             \n",
      " 48  qtd_userid             279316 non-null   float64            \n",
      " 49  qtd_text               285887 non-null   object             \n",
      " 50  qtd_hashtag            1678460 non-null  object             \n",
      " 51  qtd_qtd_count          1678460 non-null  int64              \n",
      " 52  qtd_rt_count           1678459 non-null  float64            \n",
      " 53  qtd_reply_count        1678459 non-null  float64            \n",
      " 54  qtd_fav_count          1678459 non-null  float64            \n",
      " 55  qtd_tweetid            285887 non-null   float64            \n",
      " 56  qtd_urls_list          1678460 non-null  object             \n",
      " 57  qtd_location           225680 non-null   object             \n",
      " 58  sent_vader             1678460 non-null  float64            \n",
      " 59  token                  1677598 non-null  object             \n",
      " 60  media_urls             1678460 non-null  object             \n",
      " 61  rt_media_urls          1678460 non-null  object             \n",
      " 62  q_media_urls           1678460 non-null  object             \n",
      " 63  state                  365639 non-null   object             \n",
      " 64  country                636181 non-null   object             \n",
      " 65  rt_state               299368 non-null   object             \n",
      " 66  rt_country             443102 non-null   object             \n",
      " 67  qtd_state              123073 non-null   object             \n",
      " 68  qtd_country            178632 non-null   object             \n",
      " 69  norm_country           636181 non-null   object             \n",
      " 70  norm_rt_country        443102 non-null   object             \n",
      " 71  norm_qtd_country       178632 non-null   object             \n",
      " 72  is_kw                  1678460 non-null  bool               \n",
      " 73  description            359581 non-null   object             \n",
      " 74  rt_user_description    185645 non-null   object             \n",
      " 75  qtd_user_description   74079 non-null    object             \n",
      " 76  acc_age                272712 non-null   float64            \n",
      "dtypes: bool(2), datetime64[ns, UTC](1), float64(15), int64(8), object(51)\n",
      "memory usage: 976.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_name</th>\n",
       "      <th>...</th>\n",
       "      <th>qtd_state</th>\n",
       "      <th>qtd_country</th>\n",
       "      <th>norm_country</th>\n",
       "      <th>norm_rt_country</th>\n",
       "      <th>norm_qtd_country</th>\n",
       "      <th>is_kw</th>\n",
       "      <th>description</th>\n",
       "      <th>rt_user_description</th>\n",
       "      <th>qtd_user_description</th>\n",
       "      <th>acc_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1220644546771591168</td>\n",
       "      <td>95655465</td>\n",
       "      <td>shaunrein</td>\n",
       "      <td>2020-01-24 09:48:33+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Shanghai (8621) 6326-9991 info@researchcmr.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>1220646659052326914</td>\n",
       "      <td>901844487315406850</td>\n",
       "      <td>friendofwinter</td>\n",
       "      <td>2020-01-24 09:56:56+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>bts, blackpink, and girlgroups</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11024</th>\n",
       "      <td>1220646239630315520</td>\n",
       "      <td>1110768577953460226</td>\n",
       "      <td>JENDERALISA</td>\n",
       "      <td>2020-01-24 09:55:16+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13401</th>\n",
       "      <td>1220643783286644736</td>\n",
       "      <td>2530100864</td>\n",
       "      <td>MSasisom</td>\n",
       "      <td>2020-01-24 09:45:31+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>1220642807930478592</td>\n",
       "      <td>150572999</td>\n",
       "      <td>jackrizley</td>\n",
       "      <td>2020-01-24 09:41:38+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>1220641695651389440</td>\n",
       "      <td>859287999539929090</td>\n",
       "      <td>zqmkni</td>\n",
       "      <td>2020-01-24 09:37:13+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>ty track’s heart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15708</th>\n",
       "      <td>1220641540063649794</td>\n",
       "      <td>1054619120753242113</td>\n",
       "      <td>TheVandelay</td>\n",
       "      <td>2020-01-24 09:36:36+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Hell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16099</th>\n",
       "      <td>1220641114576699392</td>\n",
       "      <td>4363890732</td>\n",
       "      <td>phiisu_</td>\n",
       "      <td>2020-01-24 09:34:54+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16470</th>\n",
       "      <td>1220640742097342464</td>\n",
       "      <td>1694181907</td>\n",
       "      <td>i_Aeoy</td>\n",
       "      <td>2020-01-24 09:33:25+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Thailand,Chonburi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17427</th>\n",
       "      <td>1220639678631727105</td>\n",
       "      <td>966319144315449349</td>\n",
       "      <td>IC_muchie</td>\n",
       "      <td>2020-01-24 09:29:12+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18477</th>\n",
       "      <td>1220638607569977344</td>\n",
       "      <td>258415882</td>\n",
       "      <td>BerniceCBC</td>\n",
       "      <td>2020-01-24 09:24:57+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Corner Brook, NL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18987</th>\n",
       "      <td>1220638024498724864</td>\n",
       "      <td>1096167035137024000</td>\n",
       "      <td>Teal96ko</td>\n",
       "      <td>2020-01-24 09:22:38+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Winner City, Winner Wonderland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20371</th>\n",
       "      <td>1220636534476439553</td>\n",
       "      <td>364117556</td>\n",
       "      <td>ukukuk_21</td>\n",
       "      <td>2020-01-24 09:16:42+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>เช็คสถานะ 👉🏻</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>1220636173946634240</td>\n",
       "      <td>999611828</td>\n",
       "      <td>NotEvilOctopus</td>\n",
       "      <td>2020-01-24 09:15:16+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Dark depths of the ocean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21418</th>\n",
       "      <td>1220635410096893952</td>\n",
       "      <td>2865086833</td>\n",
       "      <td>viralvm69</td>\n",
       "      <td>2020-01-24 09:12:14+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweetid               userid     screen_name  \\\n",
       "1771   1220644546771591168             95655465       shaunrein   \n",
       "10596  1220646659052326914   901844487315406850  friendofwinter   \n",
       "11024  1220646239630315520  1110768577953460226     JENDERALISA   \n",
       "13401  1220643783286644736           2530100864        MSasisom   \n",
       "14390  1220642807930478592            150572999      jackrizley   \n",
       "15547  1220641695651389440   859287999539929090          zqmkni   \n",
       "15708  1220641540063649794  1054619120753242113     TheVandelay   \n",
       "16099  1220641114576699392           4363890732         phiisu_   \n",
       "16470  1220640742097342464           1694181907          i_Aeoy   \n",
       "17427  1220639678631727105   966319144315449349       IC_muchie   \n",
       "18477  1220638607569977344            258415882      BerniceCBC   \n",
       "18987  1220638024498724864  1096167035137024000        Teal96ko   \n",
       "20371  1220636534476439553            364117556       ukukuk_21   \n",
       "20708  1220636173946634240            999611828  NotEvilOctopus   \n",
       "21418  1220635410096893952           2865086833       viralvm69   \n",
       "\n",
       "                           date lang  \\\n",
       "1771  2020-01-24 09:48:33+00:00   en   \n",
       "10596 2020-01-24 09:56:56+00:00   en   \n",
       "11024 2020-01-24 09:55:16+00:00   en   \n",
       "13401 2020-01-24 09:45:31+00:00   en   \n",
       "14390 2020-01-24 09:41:38+00:00   en   \n",
       "15547 2020-01-24 09:37:13+00:00   en   \n",
       "15708 2020-01-24 09:36:36+00:00   en   \n",
       "16099 2020-01-24 09:34:54+00:00   en   \n",
       "16470 2020-01-24 09:33:25+00:00   en   \n",
       "17427 2020-01-24 09:29:12+00:00   en   \n",
       "18477 2020-01-24 09:24:57+00:00   en   \n",
       "18987 2020-01-24 09:22:38+00:00   en   \n",
       "20371 2020-01-24 09:16:42+00:00   en   \n",
       "20708 2020-01-24 09:15:16+00:00   en   \n",
       "21418 2020-01-24 09:12:14+00:00   en   \n",
       "\n",
       "                                             location place_id place_url  \\\n",
       "1771   Shanghai (8621) 6326-9991 info@researchcmr.com      NaN       NaN   \n",
       "10596                  bts, blackpink, and girlgroups      NaN       NaN   \n",
       "11024                                             NaN      NaN       NaN   \n",
       "13401                                             NaN      NaN       NaN   \n",
       "14390                               Bangkok, Thailand      NaN       NaN   \n",
       "15547                                ty track’s heart      NaN       NaN   \n",
       "15708                                            Hell      NaN       NaN   \n",
       "16099                                             NaN      NaN       NaN   \n",
       "16470                               Thailand,Chonburi      NaN       NaN   \n",
       "17427                                           India      NaN       NaN   \n",
       "18477                                Corner Brook, NL      NaN       NaN   \n",
       "18987                  Winner City, Winner Wonderland      NaN       NaN   \n",
       "20371                                    เช็คสถานะ 👉🏻      NaN       NaN   \n",
       "20708                        Dark depths of the ocean      NaN       NaN   \n",
       "21418                                   Mumbai, India      NaN       NaN   \n",
       "\n",
       "      place_type place_name  ... qtd_state qtd_country norm_country  \\\n",
       "1771         NaN        NaN  ...       NaN         NaN          NaN   \n",
       "10596        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "11024        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "13401        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "14390        NaN        NaN  ...       NaN         NaN     Thailand   \n",
       "15547        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "15708        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "16099        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "16470        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "17427        NaN        NaN  ...       NaN         NaN        India   \n",
       "18477        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "18987        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "20371        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "20708        NaN        NaN  ...       NaN         NaN          NaN   \n",
       "21418        NaN        NaN  ...       NaN         NaN        India   \n",
       "\n",
       "      norm_rt_country norm_qtd_country is_kw description  rt_user_description  \\\n",
       "1771              NaN              NaN  True         NaN                  NaN   \n",
       "10596     Switzerland              NaN  True         NaN                  NaN   \n",
       "11024     Switzerland              NaN  True         NaN                  NaN   \n",
       "13401     Switzerland              NaN  True         NaN                  NaN   \n",
       "14390     Switzerland              NaN  True         NaN                  NaN   \n",
       "15547     Switzerland              NaN  True         NaN                  NaN   \n",
       "15708             NaN              NaN  True         NaN                  NaN   \n",
       "16099     Switzerland              NaN  True         NaN                  NaN   \n",
       "16470     Switzerland              NaN  True         NaN                  NaN   \n",
       "17427     Switzerland              NaN  True         NaN                  NaN   \n",
       "18477     Switzerland              NaN  True         NaN                  NaN   \n",
       "18987     Switzerland              NaN  True         NaN                  NaN   \n",
       "20371     Switzerland              NaN  True         NaN                  NaN   \n",
       "20708     Switzerland              NaN  True         NaN                  NaN   \n",
       "21418     Switzerland              NaN  True         NaN                  NaN   \n",
       "\n",
       "      qtd_user_description  acc_age  \n",
       "1771                   NaN      NaN  \n",
       "10596                  NaN      NaN  \n",
       "11024                  NaN      NaN  \n",
       "13401                  NaN      NaN  \n",
       "14390                  NaN      NaN  \n",
       "15547                  NaN      NaN  \n",
       "15708                  NaN      NaN  \n",
       "16099                  NaN      NaN  \n",
       "16470                  NaN      NaN  \n",
       "17427                  NaN      NaN  \n",
       "18477                  NaN      NaN  \n",
       "18987                  NaN      NaN  \n",
       "20371                  NaN      NaN  \n",
       "20708                  NaN      NaN  \n",
       "21418                  NaN      NaN  \n",
       "\n",
       "[15 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012d461-1ca1-4765-a507-b151474e896f",
   "metadata": {},
   "source": [
    "### 00B. Converting important columns\n",
    "Create a YMD column of just the year, month, and date of tweet posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b074bc8-7627-4250-97e5-119260a8770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Date Posted column of just Year, Month, Date\n",
    "\n",
    "data['date_ymd'] = data['date'].dt.strftime('%Y-%m-%d')\n",
    "data['date_ymd'] = pd.to_datetime(data['date_ymd'], format='%Y-%m-%d')\n",
    "\n",
    "## Creating Account Created column of just Year, Month, Date\n",
    "def convert_to_ymd(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "    return date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "data['acc_created_ymd'] = data['account_creation_date'].apply(convert_to_ymd)\n",
    "data['acc_created_ymd'] = pd.to_datetime(data['acc_created_ymd'], format='%Y-%m-%d')\n",
    "\n",
    "## Creating Text column without Hyperlink\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'https?://\\S+', '', text)\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea50df5-58d1-422b-ba68-faae9da0822e",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81e7ab-f941-4970-9333-7c5a7f07b488",
   "metadata": {},
   "source": [
    "### 01. Find first occurrence of each hashtag and compare it to the first news article about the hate crimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52c425-be7a-4e49-a393-bea688e8ba10",
   "metadata": {},
   "source": [
    "#### 01A. Exploring hashtags\n",
    "\n",
    "For #stopasianhate, there are many variations of anti-asian racism occurences. We wanted to search to see the variations of anti-asian racism. For COVID-19, we found most hashtags contain \"covid\" or \"coronavirus\". For BLM, we chose \"blm\" and \"blacklives\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa64c81a-a246-403d-afda-77787ab4460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create df of just #BLM-related tweets\n",
    "blm = data[data[\"hashtag\"].str.contains(\"black|blm|george floyd|derek chauvin\", case = False, na = False)]\n",
    "testingblm = blm[[\"hashtag\", \"date_ymd\", \"cleaned_text\"]].sort_values(by = \"date_ymd\").reset_index()\n",
    "\n",
    "## Create df of just #StopAsianHate-related tweets\n",
    "asian = data[data[\"hashtag\"].str.contains(\"asianlives|yellowlives|stopasianhate|stopaapihate\", case = False, na = False)]\n",
    "testingasian = asian[[\"hashtag\", \"date_ymd\", \"cleaned_text\"]].sort_values(by = \"date_ymd\").reset_index()\n",
    "\n",
    "## Create df of just #COVID-related tweets\n",
    "covid = data[data[\"hashtag\"].str.contains(\"covid|coronavirus|pandemic|pfizer|moderna|omicron variant|delta variant\", case = False, na = False)]\n",
    "testingcovid = covid[[\"hashtag\", \"date_ymd\", \"cleaned_text\"]].sort_values(by = \"date_ymd\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a1f317-9e26-491a-8002-177dd967e63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Coronachan1: @MisterAntiBully I went there and coughed on blacks so people couldn't call me racist. #sjw #coronavirus #BlackLivesMatter\n",
      "Wave of racist attacks against Asian Americans in wake of coronavirus outbreak  We say NO to #RacialDiscrimination  #StopBeingRacist #AsianLivesMatters #AsianLivesMatter #BlackLivesMatters #BlackLivesMatter #RacialHarmonyIsImportant  \n",
      "RT @WHO: @DrTedros Reduce your risk of #coronavirus infection  \n"
     ]
    }
   ],
   "source": [
    "#Testing - pull a random tweet and see the text\n",
    "print(testingblm.iloc[3, 3])\n",
    "print(testingasian.iloc[3, 3])\n",
    "print(testingcovid.iloc[3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5074674-8b68-4ecb-9028-d14168c8fe21",
   "metadata": {},
   "source": [
    "#### 01B. Defining a function to find the first occurrence within each hashtag subset\n",
    "\n",
    "This variable will be used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd9348-abdd-4b37-b79f-dd33ec508701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## hashtag: takes in a list of strings of hashtags\n",
    "def first_hashtag(df):\n",
    "\n",
    "    #select just the first occurrence per day\n",
    "    first_occurrences = df.drop_duplicates(subset = 'hashtag', keep = 'first').reset_index()\n",
    "    first_date = first_occurrences.iloc[0, 3]\n",
    "    \n",
    "    return first_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613d875-e2a4-49f9-9728-dc3fe6e9706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_first = first_hashtag(testingblm)\n",
    "print(blm_first)\n",
    "\n",
    "covid_first = first_hashtag(testingcovid)\n",
    "print(covid_first)\n",
    "\n",
    "sah_first = first_hashtag(testingasian)\n",
    "print(sah_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b5c6e-894a-41b5-b4de-fbb342043ae4",
   "metadata": {},
   "source": [
    "* First occurrence of #BLM-related hashtags: 2020-01-27 (January 27 2020)\n",
    "* First occurrence of #COVID-19-related hashtage: 2020-01-23 (January 23 2020)\n",
    "* First occurrence of #StopAsianHate-related hashtags: 2020-02-05 (February 5 2020)\n",
    "\n",
    "To compare with news articles and timelines:\n",
    "\n",
    "* [CDC COVID-19 Timeline](https://www.cdc.gov/museum/timeline/covid19.html) \n",
    "* [Georgetown BLM Timeline](https://repository.library.georgetown.edu/bitstream/handle/10822/1040691/Black%20Lives%20Matter%20Timeline%20.pdf?sequence=1)\n",
    "* [Stop AAPI Hate Project's Origins](https://stopaapihate.org/our-origins/)\n",
    "* [Anti-Asian Hate Crime During the COVID-19 Pandemic: Exploring the Reproduction of Inequality](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7364747/)\n",
    "* [Vox Article on Stop Asian Hate Movement's Trajectory](https://www.vox.com/22820364/stop-asian-hate-movement-atlanta-shootings)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a40dd-2c1b-4b44-8593-d0bd0eeef865",
   "metadata": {},
   "source": [
    "### 02. What is the relationship between the onset of these current events and the creation of twitter accounts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c90683-e8a8-4e85-b29e-2ff09c8eedc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def creation_df(df, first_date):\n",
    "    #assumption: screen_names don't change over time\n",
    "    unique_accounts = df.drop_duplicates(subset = ['userid', 'screen_name'], keep = 'first').reset_index()\n",
    "    dat = unique_accounts[[\"userid\", \"screen_name\", \"acc_created_ymd\", \"cleaned_text\", \"hashtag\"]].sort_values(by = 'acc_created_ymd').reset_index(drop=True)\n",
    "    dat['acc_created_ymd'] = pd.to_datetime(dat['acc_created_ymd'])\n",
    "    created = dat.set_index('acc_created_ymd').resample('D').size().reset_index(name='acc_created_counts')\n",
    "    created_clean = created[created[\"acc_created_ymd\"] >= first_date].reset_index(drop=True)\n",
    "    return pd.DataFrame(created_clean)\n",
    "\n",
    "blm_created = creation_df(blm, blm_first)\n",
    "asian_created = creation_df(asian, sah_first)\n",
    "covid_created = creation_df(covid, covid_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a750ca3-b307-4d00-9fdf-bc6d01b28ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_events():\n",
    "    events = pd.DataFrame([{'Health Emergency': '30-01-2020', 'George Floyd Passes Away': '05-25-2020',\n",
    "                        'Atlanta Shootings': '16-03-2021', 'Pandemic': '03-11-2020', 'OMICRON Variant': '24-11-2021',\n",
    "                        'BLM Protests Across Country': '06-06-2020', 'Chauvin for New Trial': '05-05-2021', \n",
    "                        'Trump COVID-19': '10-02-2020','DELTA Variant': '06-15-2021'}])\n",
    "\n",
    "    # Y-axis range calculation for text placement\n",
    "    y_min, y_max = plt.ylim()\n",
    "    y_text_placement = y_max + (y_max - y_min) * 0.05  # Adjusting text placement above the top\n",
    "\n",
    "    # Overlay each event\n",
    "    for event, date in events.items():\n",
    "        date = pd.to_datetime(date)\n",
    "        plt.axvline(date, color='purple', linestyle='--', linewidth=1)\n",
    "        plt.text(date, y_text_placement, event, rotation=90, verticalalignment='bottom', horizontalalignment='right',\n",
    "             color='purple', fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb482f-24d3-40a2-b5e5-0e9c457ac440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_created['acc_created_ymd'], blm_created['acc_created_counts'], label='#BLM Tweeters Account Creation')\n",
    "plt.plot(asian_created['acc_created_ymd'], asian_created['acc_created_counts'], label='#StopAsianHate Tweeters Account Creation')\n",
    "plt.plot(covid_created['acc_created_ymd'], covid_created['acc_created_counts'], label='#COVID-19 Tweeters Account Creation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accounts Created')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea8a0f-234c-43bd-80e8-ba3807dabe6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find account creation for each day\n",
    "daily_accs_clean = creation_df(data, covid_first)\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_accs_clean['acc_created_ymd'], daily_accs_clean['acc_created_counts'], label='Account Creation Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accounts Created')\n",
    "plt.tight_layout()\n",
    "plot_events()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001a6ac-c865-404a-b663-b791a5d7ecd3",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79aa55-affe-4b12-b7ab-caa59a53e917",
   "metadata": {},
   "source": [
    "### 03. What is the relationship between the onset of these current events and the volume of tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d033db-c355-4e9e-946f-4bb7ddff1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_df(df):\n",
    "    dat = df[[\"hashtag\", \"date_ymd\", \"text\"]].sort_values(by = \"date_ymd\").reset_index(drop=True)\n",
    "    volume = dat.resample('D', on='date_ymd').size().reset_index(name = 'tweet_count')\n",
    "    return pd.DataFrame(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dcd10-7066-464a-9244-ffe55c31fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not sure if this is being used\n",
    "\n",
    "def filtr(dat, start_date, end_date):\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    filtr_dat = dat[dat['date_ymd'].between(start_date, end_date)]\n",
    "    return pd.DataFrame(filtr_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505963ef-d2d4-43d4-bc68-025a11217f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_volume = volume_df(blm)\n",
    "asian_volume = volume_df(asian)\n",
    "covid_volume = volume_df(covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8be907-3f5f-43bb-af28-5a8dfbeebd88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_volume['date_ymd'], blm_volume['tweet_count'], label='#BLM Tweet Volume')\n",
    "plt.plot(asian_volume['date_ymd'], asian_volume['tweet_count'], label='#StopAsianHate Tweet Volume')\n",
    "plt.plot(covid_volume['date_ymd'], covid_volume['tweet_count'], label='#COVID-19 Tweet Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylim(0, 7500)\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63790d46-4ae5-456f-919c-f0ef3c68e07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find tweet count for each day\n",
    "daily_tweets = data.resample('D', on='date_ymd').size().reset_index(name='tweet_count')\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_tweets['date_ymd'], daily_tweets['tweet_count'], label='Tweet Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.tight_layout()\n",
    "plot_events()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ff324-aa24-4ac8-8313-951796dddd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_tweets = daily_tweets.merge(blm_volume, on='date_ymd', how='outer', suffixes=('_all', '_blm'))\\\n",
    "               .merge(asian_volume, on='date_ymd', how='outer', suffixes=('', '_asian'))\n",
    "\n",
    "merged_tweets = merged_tweets.rename(columns={\n",
    "    'tweet_count': 'tweet_count_asian'\n",
    "})\n",
    "\n",
    "merged_tweets[\"prop_blm\"] = (merged_tweets[\"tweet_count_blm\"] / merged_tweets[\"tweet_count_all\"]) * 100\n",
    "merged_tweets[\"prop_asian\"] = (merged_tweets[\"tweet_count_asian\"] / merged_tweets[\"tweet_count_all\"]) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_tweets['date_ymd'], merged_tweets['prop_blm'], label='Percent (%) of #BLM-related Tweets')\n",
    "plt.plot(merged_tweets['date_ymd'], merged_tweets['prop_asian'], label='Percent (%) of #StopAsianHate-related Tweets')\n",
    "plot_events()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent (%) of Tweets')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42e1d9-77dc-4eee-83ae-6d9dafd64148",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### 04: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b7827-58fe-403f-8256-c3b3ef22ea70",
   "metadata": {},
   "source": [
    "#### Polarity and Subjectivity Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d50c4-7661-4f56-9b3f-fc94aac8bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweets):\n",
    "    polarity = []\n",
    "    subjectivity = []\n",
    "    \n",
    "    for tweet in tweets['cleaned_text']:\n",
    "        pol = TextBlob(tweet).sentiment.polarity\n",
    "        polarity.append(pol)\n",
    "        subj = TextBlob(tweet).sentiment.subjectivity\n",
    "        subjectivity.append(subj)\n",
    "        \n",
    "    return polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a28c1-870f-49bf-adab-a994c8749747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analyze sentiment\n",
    "blm_sent = sentiment(blm)\n",
    "asian_sent = sentiment(asian)\n",
    "covid_sent = sentiment(covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef76eb-6b0f-4d28-99a6-f52b132eb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_polsubj(senti_list):\n",
    "    polarity_list = senti_list[0]\n",
    "    subjectivity_list = senti_list[1]\n",
    "\n",
    "    polsub_df = pd.DataFrame({\n",
    "        'polarity': polarity_list,\n",
    "        'subjectivity': subjectivity_list}).reset_index()\n",
    "    \n",
    "    return polsub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379e6ac-179b-472a-b0e5-0b9a3e78c247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blm_polsub_scores = append_polsubj(blm_sent)\n",
    "blm_polsub = pd.concat([blm.reset_index(), blm_polsub_scores], axis = 1).sort_values(by = \"polarity\", ascending = False).reset_index(drop = True)\n",
    "blm_polsub\n",
    "\n",
    "sah_polsub_scores = append_polsubj(asian_sent)\n",
    "sah_polsub = pd.concat([asian.reset_index(), sah_polsub_scores], axis = 1).sort_values(by = \"polarity\", ascending = False).reset_index(drop = True)\n",
    "sah_polsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a5223-f85f-4166-a0af-e3b69af1ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for df1\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter_df1 = plt.scatter(blm_polsub['polarity'], blm_polsub['subjectivity'], color='blue', label='#BLM Sentiments', s=10, alpha=0.25)\n",
    "\n",
    "# Scatter plot for df2\n",
    "scatter_df2 = plt.scatter(sah_polsub['polarity'], sah_polsub['subjectivity'], color='red', label='#StopAsianHate Sentiments', s=10, alpha=0.25)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Subjectivity')\n",
    "plt.title('Scatter Plot of Polarity vs Subjectivity')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54498672-e66a-4001-a27d-264185e6dbfb",
   "metadata": {},
   "source": [
    "### Positive and Negative Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285118e4-2a59-43c3-8be2-4be5603a7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_df(df, nrow):\n",
    "    unique_text = df.drop_duplicates(subset = [\"cleaned_text\"], keep = 'first').reset_index()\n",
    "    dat = unique_text[[\"cleaned_text\", \"hashtag\"]].reset_index(drop=True)\n",
    "    random_sample = dat.sample(n=nrow)\n",
    "    return pd.DataFrame(random_sample)\n",
    "\n",
    "blm_senti_df = sentiment_df(blm, 500)\n",
    "sah_senti_df = sentiment_df(asian, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8cf00-5d59-4523-b981-0d1efe86b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullnames(tweet):\n",
    "    #Find the named entities\n",
    "    spacy_press = nlp(tweet)\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(ent.text) for ent in spacy_press.ents) + r')\\b'\n",
    "\n",
    "    #Remove named entities\n",
    "    clean_tweet = re.sub(pattern, '', tweet)\n",
    "\n",
    "    #Score the sentiment\n",
    "    sent_obj = SentimentIntensityAnalyzer()\n",
    "    sent_tweet = sent_obj.polarity_scores(clean_tweet)\n",
    "    return sent_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc128afb-ed83-4d87-8531-7c4935f6179a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blm_sentiments = []\n",
    "sah_sentiments = []\n",
    "\n",
    "for release in blm_senti_df[\"cleaned_text\"].tolist():\n",
    "    blm_sentiments.append(pullnames(release))\n",
    "\n",
    "for release in sah_senti_df[\"cleaned_text\"].tolist():\n",
    "    sah_sentiments.append(pullnames(release))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8176ada-9bba-42c0-9015-23f53eaaff14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_sentis(senti_list):\n",
    "    neg_list = [dict['neg'] for dict in senti_list]\n",
    "    neu_list = [dict['neu'] for dict in senti_list]\n",
    "    pos_list = [dict['pos'] for dict in senti_list]\n",
    "    compound_list = [dict['compound'] for dict in senti_list]\n",
    "\n",
    "    sentiments_df = pd.DataFrame({\n",
    "        'neg': neg_list,\n",
    "        'neu': neu_list,\n",
    "        'pos': pos_list,\n",
    "        'compound_value': compound_list}).reset_index()\n",
    "    \n",
    "    return sentiments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f191c9-f50e-44a2-ac3c-09d5019ce033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blm_scores = append_sentis(blm_sentiments)\n",
    "blm_senti_score = pd.concat([blm_senti_df.reset_index(), blm_scores], axis = 1).sort_values(by = \"neg\", ascending = False).reset_index(drop = True)\n",
    "\n",
    "sah_scores = append_sentis(sah_sentiments)\n",
    "sah_senti_score = pd.concat([sah_senti_df.reset_index(), sah_scores], axis = 1).sort_values(by = \"neg\", ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75dc06-db55-4010-bd9e-9fb8d03608b0",
   "metadata": {},
   "source": [
    "#### Sentiment Score Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510a95a-0594-421a-a520-f121d73eb248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot for BLM\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter_blm = plt.scatter(blm_senti_score['pos'], blm_senti_score['neg'], color='blue', label='BLM', s=50, alpha=0.5)\n",
    "\n",
    "# Scatter plot for SAH\n",
    "scatter_sah = plt.scatter(sah_senti_score['pos'], sah_senti_score['neg'], color='red', label='SAH', s=50, alpha=0.5)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Positive Sentiment')\n",
    "plt.ylabel('Negative Sentiment')\n",
    "plt.title('Sentiment Analysis')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09daf8-fad6-4924-b94e-5bf5d3a938e5",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "#### 05. Bot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52736ef6-0b3f-46bc-a71d-3d5b338e818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"/Users/emmanguyen/Downloads/raw_scores-english.csv\"\n",
    "bots = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061bd77-9966-493c-9aaf-96e5b9b7b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bots(df):\n",
    "    bots_names = bots[\"screen_name\"]\n",
    "    tweet_names = df[\"screen_name\"]\n",
    "\n",
    "    # Convert the screen names to sets for faster lookup\n",
    "    bots_set = set(bots_names)\n",
    "    tweet_set = set(tweet_names)\n",
    "\n",
    "    # Find the common screen names\n",
    "    bots_indf = bots_set.intersection(tweet_set)\n",
    "\n",
    "    # Convert the common screen names back to a list\n",
    "    bots_indf_list = list(bots_indf)\n",
    "\n",
    "    # Pull out the tweets corresponding to the common screen names\n",
    "    bot_tweets = df[df[\"screen_name\"].isin(bots_indf_list)]\n",
    "\n",
    "    return bot_tweets\n",
    "\n",
    "def remove_bots(botdf, df):\n",
    "    # Get the indices of rows with common screen names in the original data dataframe\n",
    "    indices_to_drop = botdf.index\n",
    "\n",
    "    # Drop the rows from the data dataframe using the indices\n",
    "    data_nobots = df.drop(indices_to_drop)\n",
    "\n",
    "    # Display the modified data dataframe\n",
    "    return data_nobots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268cd659-a2a6-494d-b647-1219c8d1b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_bots = get_bots(blm)\n",
    "sah_bots = get_bots(asian)\n",
    "\n",
    "blm_nobots = remove_bots(blm_bots, blm)\n",
    "sah_nobots = remove_bots(sah_bots, asian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7b85e-a842-482e-9c89-79bbcb3d3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_nobots_created = creation_df(blm_nobots, blm_first)\n",
    "sah_nobots_created = creation_df(sah_nobots, sah_first)\n",
    "\n",
    "blm_nobots_vol = volume_df(blm_nobots)\n",
    "sah_nobots_vol = volume_df(sah_nobots)\n",
    "\n",
    "blm_bots_created = creation_df(blm_bots, blm_first)\n",
    "sah_bots_created = creation_df(sah_bots, sah_first)\n",
    "\n",
    "blm_bots_vol = volume_df(blm_bots)\n",
    "sah_bots_vol = volume_df(sah_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3677b0a-ca6a-431e-b050-2a64184fc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account Creation no bots\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_nobots_created['acc_created_ymd'], blm_nobots_created['acc_created_counts'], label='#BLM Tweeters Account Creation Without Bots')\n",
    "plt.plot(sah_nobots_created['acc_created_ymd'], sah_nobots_created['acc_created_counts'], label='#StopAsianHate Tweeters Account Creation Without Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accounts Created')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60901a-1ac0-4da8-beec-44e35fb14e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet Volume no bots\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_nobots_vol['date_ymd'], blm_nobots_vol['tweet_count'], label='#BLM Tweet Volume Without Bots')\n",
    "plt.plot(sah_nobots_vol['date_ymd'], sah_nobots_vol['tweet_count'], label='#StopAsianHate Tweet Volume Without Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylim(0, 7500)\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc5af0-3f01-463c-902f-78647a9212d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account Creation Bots vs. No Bots - BLM\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_nobots_created['acc_created_ymd'], blm_nobots_created['acc_created_counts'], label='#BLM Tweeters Account Creation Without Bots')\n",
    "plt.plot(blm_bots_created['acc_created_ymd'], blm_bots_created['acc_created_counts'], label='#BLM Tweeters Account Creation Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accounts Created')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc44c3-7006-4261-8f54-351cce35bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account Creation Bots vs. No Bots - Stop Asian Hate\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sah_nobots_created['acc_created_ymd'], sah_nobots_created['acc_created_counts'], label='#StopAsianHate Tweeters Account Creation Without Bots')\n",
    "plt.plot(sah_bots_created['acc_created_ymd'], sah_bots_created['acc_created_counts'], label='#StopAsianHate Tweeters Account Creation Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accounts Created')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8472217-35eb-4ac5-a416-c0a27fcb2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet Volume Bots vs. No Bots - BLM\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(blm_nobots_vol['date_ymd'], blm_nobots_vol['tweet_count'], label='#BLM Tweet Volume Without Bots')\n",
    "plt.plot(blm_bots_vol['date_ymd'], blm_bots_vol['tweet_count'], label='#BLM Tweet Volume With Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylim(0, 7500)\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eada516-312f-43ff-a21a-d892bfdfcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet Volume Bots vs. No Bots - StopAsianHate\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sah_nobots_vol['date_ymd'], sah_nobots_vol['tweet_count'], label='#StopAsianHate Tweet Volume Without Bots')\n",
    "plt.plot(sah_bots_vol['date_ymd'], sah_bots_vol['tweet_count'], label='#StopAsianHate Tweet Volume With Bots')\n",
    "plt.xlabel('Date')\n",
    "plt.ylim(0, 7500)\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plot_events()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6aeb0-5410-4e35-8990-958878b57d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_blm_tweets = blm_volume.merge(blm_nobots_vol, on='date_ymd', how='outer', suffixes=('_blm', '_nobots'))\\\n",
    "                   .merge(blm_bots_vol, on='date_ymd', how='outer', suffixes=('', '_bots'))\n",
    "\n",
    "merged_blm_tweets = merged_blm_tweets.rename(columns={\n",
    "    'tweet_count': 'tweet_count_bots'\n",
    "})\n",
    "\n",
    "merged_blm_tweets[\"prop_nobots\"] = (merged_blm_tweets[\"tweet_count_nobots\"] / merged_blm_tweets[\"tweet_count_blm\"]) * 100\n",
    "merged_blm_tweets[\"prop_bots\"] = (merged_blm_tweets[\"tweet_count_bots\"] / merged_blm_tweets[\"tweet_count_blm\"]) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_blm_tweets['date_ymd'], merged_blm_tweets['prop_nobots'], label='Percent (%) of #BLM-related Tweets from Bots')\n",
    "plt.plot(merged_blm_tweets['date_ymd'], merged_blm_tweets['prop_bots'], label='Percent (%) of #BLM-related Tweets from Humans')\n",
    "plot_events()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent (%) of Tweets')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e03e7-4865-4568-9f69-c38cf2201a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sah_tweets = asian_volume.merge(sah_nobots_vol, on='date_ymd', how='outer', suffixes=('_sah', '_nobots'))\\\n",
    "                   .merge(sah_bots_vol, on='date_ymd', how='outer', suffixes=('', '_bots'))\n",
    "\n",
    "merged_sah_tweets = merged_sah_tweets.rename(columns={\n",
    "    'tweet_count': 'tweet_count_bots'\n",
    "})\n",
    "\n",
    "merged_sah_tweets[\"prop_nobots\"] = (merged_sah_tweets[\"tweet_count_nobots\"] / merged_sah_tweets[\"tweet_count_sah\"]) * 100\n",
    "merged_sah_tweets[\"prop_bots\"] = (merged_sah_tweets[\"tweet_count_bots\"] / merged_sah_tweets[\"tweet_count_sah\"]) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_sah_tweets['date_ymd'], merged_sah_tweets['prop_nobots'], label='Percent (%) of #StopAsianHate-related Tweets from Bots')\n",
    "plt.plot(merged_sah_tweets['date_ymd'], merged_sah_tweets['prop_bots'], label='Percent (%) of #StopAsianHate-related Tweets from Humans')\n",
    "plot_events()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent (%) of Tweets')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
